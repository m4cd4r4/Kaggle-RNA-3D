{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model - RNA 3D Structure Prediction\n",
    "\n",
    "This notebook builds a baseline model for predicting RNA 3D structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data/raw')\n",
    "MODEL_DIR = Path('../models')\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Prepare the dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNADataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for RNA sequences and 3D structures.\"\"\"\n",
    "    \n",
    "    def __init__(self, sequences, targets=None):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "        \n",
    "        # Nucleotide to index mapping\n",
    "        self.vocab = {'A': 0, 'U': 1, 'G': 2, 'C': 3, 'N': 4}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def encode_sequence(self, seq):\n",
    "        \"\"\"Convert RNA sequence to numerical encoding.\"\"\"\n",
    "        return torch.tensor([self.vocab.get(n, 4) for n in seq], dtype=torch.long)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        x = self.encode_sequence(seq)\n",
    "        \n",
    "        if self.targets is not None:\n",
    "            y = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "            return x, y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Architecture\n",
    "\n",
    "Define a simple baseline model using LSTM/Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNA3DPredictor(nn.Module):\n",
    "    \"\"\"Baseline model for RNA 3D structure prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size=5, embed_dim=128, hidden_dim=256, num_layers=4, dropout=0.2):\n",
    "        super(RNA3DPredictor, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim, \n",
    "            hidden_dim, \n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Output layer (3D coordinates: x, y, z per nucleotide)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len)\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        lstm_out, _ = self.lstm(embedded)  # (batch, seq_len, hidden_dim*2)\n",
    "        coords = self.fc(lstm_out)  # (batch, seq_len, 3)\n",
    "        return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Loop\n",
    "\n",
    "Train the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_x, batch_y in tqdm(dataloader, desc='Training'):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in tqdm(dataloader, desc='Validation'):\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# TODO: Load actual data\n",
    "# train_dataset = RNADataset(train_sequences, train_targets)\n",
    "# val_dataset = RNADataset(val_sequences, val_targets)\n",
    "# \n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Initialize model\n",
    "model = RNA3DPredictor(\n",
    "    vocab_size=5,\n",
    "    embed_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=4,\n",
    "    dropout=0.2\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_val_loss = float('inf')\n",
    "# \n",
    "# for epoch in range(EPOCHS):\n",
    "#     train_loss = train_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "#     val_loss = validate(model, val_loader, criterion, DEVICE)\n",
    "#     \n",
    "#     print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "#     print(f\"  Train Loss: {train_loss:.6f}\")\n",
    "#     print(f\"  Val Loss: {val_loss:.6f}\")\n",
    "#     \n",
    "#     # Save best model\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         torch.save(model.state_dict(), MODEL_DIR / 'baseline_best.pth')\n",
    "#         print(\"  Saved best model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "# model.load_state_dict(torch.load(MODEL_DIR / 'baseline_best.pth'))\n",
    "# model.eval()\n",
    "# \n",
    "# # Generate predictions for test set\n",
    "# test_dataset = RNADataset(test_sequences)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "# \n",
    "# predictions = []\n",
    "# with torch.no_grad():\n",
    "#     for batch_x in tqdm(test_loader, desc='Generating predictions'):\n",
    "#         batch_x = batch_x.to(DEVICE)\n",
    "#         outputs = model(batch_x)\n",
    "#         predictions.append(outputs.cpu().numpy())\n",
    "# \n",
    "# predictions = np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({\n",
    "#     'id': test_ids,\n",
    "#     'prediction': predictions.tolist()\n",
    "# })\n",
    "# \n",
    "# submission.to_csv('../submissions/baseline_submission.csv', index=False)\n",
    "# print(\"Submission saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
